{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for data scraping and saving it into a csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import ast\n",
    "\n",
    "# Set up the WebDriver for Selenium\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Function to log in to the website using Selenium\n",
    "def login_with_selenium():\n",
    "    driver.get('https://central1.recallmax.com/centralServer/request/admin/public/user/login.html')\n",
    "    username = driver.find_element(By.ID, 'username')\n",
    "    password = driver.find_element(By.ID, 'password')\n",
    "    username.send_keys('username_revoked')\n",
    "    password.send_keys('password_revoked')\n",
    "    login_button = driver.find_element(By.XPATH, '//button[@type=\"submit\"]')\n",
    "    login_button.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "# Function to extract cookies and use them in requests\n",
    "def get_authenticated_session():\n",
    "    selenium_cookies = driver.get_cookies()\n",
    "    session = requests.Session()\n",
    "    for cookie in selenium_cookies:\n",
    "        session.cookies.set(cookie['name'], cookie['value'])\n",
    "    return session\n",
    "\n",
    "# Function to fetch all survey responses for a specific year\n",
    "def get_survey_responses(session, year):\n",
    "    url = \"https://can5.recallmax.com/rsm/request/dash/secure/survey/surveyResponsesTable\"\n",
    "    params = {\n",
    "        \"accountId\": 67640,\n",
    "        \"period\": year,\n",
    "        \"_\": int(time.time() * 1000)\n",
    "    }\n",
    "    response = session.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            return response.json().get(\"data\", [])\n",
    "        except ValueError:\n",
    "            print(f\"Failed to parse JSON response for year {year}.\")\n",
    "            return []\n",
    "    else:\n",
    "        print(f\"Failed to fetch survey responses for year {year}. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Function to fetch survey details for each survey\n",
    "def get_survey_details(session, survey_id):\n",
    "    url = \"https://can5.recallmax.com/rsm/request/dash/secure/survey/surveyResponseDetails\"\n",
    "    params = {\"accountId\": 67640, \"surveyId\": survey_id}\n",
    "    response = session.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            return response.json()\n",
    "        except ValueError:\n",
    "            print(f\"Failed to parse survey details for survey ID {survey_id}.\")\n",
    "            return {}\n",
    "    else:\n",
    "        print(f\"Failed to fetch details for survey ID {survey_id}. Status code: {response.status_code}\")\n",
    "        return {}\n",
    "\n",
    "# Scrape, clean, and structure survey data into a DataFrame\n",
    "def scrape_surveys():\n",
    "    login_with_selenium()\n",
    "    session = get_authenticated_session()\n",
    "    all_survey_data = []\n",
    "\n",
    "    for year in range(2019, 2025):\n",
    "        survey_responses = get_survey_responses(session, year)\n",
    "        if not survey_responses:\n",
    "            continue\n",
    "        for survey in survey_responses:\n",
    "            survey_id = survey.get(\"surveyId\")\n",
    "            if survey_id:\n",
    "                survey_details = get_survey_details(session, survey_id)\n",
    "                if survey_details:\n",
    "                    survey_data = {**survey, **survey_details, \"year\": year}\n",
    "                    all_survey_data.append(survey_data)\n",
    "\n",
    "    # Create and clean DataFrame\n",
    "    df = pd.DataFrame(all_survey_data)\n",
    "    df.drop(['contacted', 'unread', 'ratingRaw', 'apptDateRaw', 'emailHref', 'avgRating', 'selectedSurveyResponseId'], axis=1, inplace=True)\n",
    "    df = df.replace(['', ' ', 'nan', 'NULL', 'N/A','NaN'], 'Null').fillna('None')\n",
    "\n",
    "    def clean_apptProv(value):\n",
    "        if isinstance(value, list) and value == [\"N/A\"]:\n",
    "            return 'None'\n",
    "        return value\n",
    "\n",
    "    df['apptProv'] = df['apptProv'].apply(clean_apptProv)\n",
    "\n",
    "    def clean_questionResponses(value):\n",
    "        if isinstance(value, dict):\n",
    "            return {k: ('NULL' if v in ['N/A', '', ' ','NULL','NaN'] else v) for k, v in value.items()}\n",
    "        return value\n",
    "\n",
    "    df['questionResponses'] = df['questionResponses'].apply(clean_questionResponses)\n",
    "    responses_df = df['questionResponses'].apply(pd.Series)\n",
    "    global updated_df \n",
    "    updated_df = pd.concat([df.drop(columns=['questionResponses']), responses_df], axis=1)\n",
    "    updated_df.to_csv('C:/AMOD/finalscraped.csv')\n",
    "    return updated_df\n",
    "\n",
    "# Function to normalize provider names\n",
    "def normalize_provider_name(provider):\n",
    "    provider = re.sub(r'\\[|\\]', '', provider)\n",
    "    provider = ' '.join(provider.split())\n",
    "    return provider.strip()\n",
    "\n",
    "# Database insertion functions\n",
    "def insert_survey(cursor, survey_id, name, email, survey_date, appointment_date):\n",
    "    cursor.execute(\"SELECT survey_id FROM surveys WHERE survey_id = %s\", (survey_id,))\n",
    "    result = cursor.fetchone()\n",
    "    if result:\n",
    "        return survey_id\n",
    "    cursor.execute(\"INSERT INTO surveys (survey_id, name, email, survey_date, appointment_date) VALUES (%s, %s, %s, %s, %s)\", (survey_id, name, email, survey_date, appointment_date))\n",
    "    return survey_id\n",
    "\n",
    "def insert_providers(cursor, provider_list):\n",
    "    provider_ids = []\n",
    "    if pd.notnull(provider_list):\n",
    "        providers = [normalize_provider_name(p) for p in provider_list.split(', ')]\n",
    "        for provider in providers:\n",
    "            cursor.execute(\"SELECT id FROM providers WHERE name = %s\", (provider,))\n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                provider_ids.append(result[0])\n",
    "            else:\n",
    "                cursor.execute(\"INSERT INTO providers (name) VALUES (%s)\", (provider,))\n",
    "                provider_ids.append(cursor.lastrowid)\n",
    "    return provider_ids\n",
    "\n",
    "def insert_response(cursor, survey_id, provider_id, comment):\n",
    "    cursor.execute(\"SELECT id FROM responses WHERE survey_id = %s AND provider_id = %s\", (survey_id, provider_id))\n",
    "    result = cursor.fetchone()\n",
    "    if result:\n",
    "        cursor.execute(\"UPDATE responses SET comment = %s WHERE id = %s\", (comment, result[0]))\n",
    "        return result[0]\n",
    "    cursor.execute(\"INSERT INTO responses (survey_id, provider_id, comment) VALUES (%s, %s, %s)\", (survey_id, provider_id, comment))\n",
    "    return cursor.lastrowid\n",
    "\n",
    "def insert_question(cursor, question_text):\n",
    "    cursor.execute(\"SELECT id FROM questions WHERE question_text = %s\", (question_text,))\n",
    "    result = cursor.fetchone()\n",
    "    if result:\n",
    "        return result[0]\n",
    "    cursor.execute(\"INSERT INTO questions (question_text) VALUES (%s)\", (question_text,))\n",
    "    return cursor.lastrowid\n",
    "\n",
    "def insert_response_detail(cursor, response_id, question_id, response_text):\n",
    "    cursor.execute(\"SELECT id FROM response_details WHERE response_id = %s AND question_id = %s\", (response_id, question_id))\n",
    "    result = cursor.fetchone()\n",
    "    if result:\n",
    "        cursor.execute(\"UPDATE response_details SET response = %s WHERE id = %s\", (response_text, result[0]))\n",
    "    else:\n",
    "        cursor.execute(\"INSERT INTO response_details (response_id, question_id, response) VALUES (%s, %s, %s)\", (response_id, question_id, response_text))\n",
    "\n",
    "# Main function to insert data into the database\n",
    "def insert_data(cursor, df):\n",
    "    question_columns = [col for col in df.columns if col not in ['contacted', 'ratingRaw', 'surveyId', 'apptDateRaw', 'name', 'rating', 'comment', 'apptDate', 'apptProv', 'email', 'emailHref', 'respDate', 'patientContacted', 'avgRating', 'selectedSurveyResponseId', 'year', 'Comments']]\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        survey_id = insert_survey(cursor, row['surveyId'], row['name'], row['email'], row['respDate'], row['apptDate'])\n",
    "        provider_ids = insert_providers(cursor, row['apptProv'])\n",
    "        for provider_id in provider_ids:\n",
    "            response_id = insert_response(cursor, survey_id, provider_id, row.get('Comments', None))\n",
    "            for question in question_columns:\n",
    "                question_id = insert_question(cursor, question)\n",
    "                response_text = row[question]\n",
    "                if pd.notnull(response_text):\n",
    "                    insert_response_detail(cursor, response_id, question_id, str(response_text))\n",
    "\n",
    "# Database connection and main process\n",
    "conn = mysql.connector.connect(user='root', password='dentalclinic', host='localhost', database='dental_clinic')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "try:\n",
    "    scrape_surveys()\n",
    "    df = pd.read_csv(\"C:/AMOD/finalscraped.csv\")\n",
    "    insert_data(cursor, df)\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(\"An error occurred:\", e)\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation to check if the data has been inserted into Mysql without any error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Load the CSV file for comparison\n",
    "df = pd.read_csv('C:/AMOD/finalscraped.csv')\n",
    "\n",
    "# Database connection setup\n",
    "conn = mysql.connector.connect(user='root', password='dentalclinic', host='localhost', database='dental_clinic')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Function to convert date format to 'YYYY-MM-DD'\n",
    "def format_date(date_value):\n",
    "    if pd.isna(date_value):\n",
    "        return None\n",
    "    return datetime.strptime(str(date_value), '%Y-%m-%d').date()\n",
    "\n",
    "# Function to normalize provider names by removing special characters and extra spaces\n",
    "def normalize_provider_name(provider):\n",
    "    provider = re.sub(r'\\[|\\]', '', provider)  \n",
    "    provider = ' '.join(provider.split()) \n",
    "\n",
    "# Test Case 1: Check Survey Record Count\n",
    "def test_survey_count():\n",
    "    unique_survey_ids = df['surveyId'].nunique()\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM surveys\")\n",
    "    db_count = cursor.fetchone()[0]\n",
    "    assert unique_survey_ids == db_count, f\"Survey count mismatch: CSV={unique_survey_ids}, DB={db_count}\"\n",
    "\n",
    "# Test Case 2: Check Provider Record Count\n",
    "def test_provider_count():\n",
    "    unique_providers = set(\n",
    "        normalize_provider_name(provider.strip()) for providers in df['apptProv'].dropna() for provider in providers.split(', ')\n",
    "    )\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM providers\")\n",
    "    db_count = cursor.fetchone()[0]\n",
    "    assert len(unique_providers) == db_count, f\"Provider count mismatch: CSV={len(unique_providers)}, DB={db_count}\"\n",
    "\n",
    "# Test Case 3: Check Response Record Count\n",
    "def test_response_count():\n",
    "    unique_responses = set()\n",
    "    for _, row in df.iterrows():\n",
    "        survey_id = row['surveyId']\n",
    "        if pd.notnull(row['apptProv']):\n",
    "            providers = row['apptProv'].split(', ')\n",
    "            for provider in providers:\n",
    "                provider_normalized = normalize_provider_name(provider.strip())\n",
    "                unique_responses.add((survey_id, provider_normalized))\n",
    "    \n",
    "    cursor.execute(\"SELECT COUNT(*) FROM responses\")\n",
    "    db_count = cursor.fetchone()[0]\n",
    "    assert len(unique_responses) == db_count, f\"Response count mismatch: CSV={len(unique_responses)}, DB={db_count}\"\n",
    "\n",
    "# Test Case 4: Check Question Record Count\n",
    "def test_question_count():\n",
    "    question_columns = [\n",
    "        col for col in df.columns if col not in [\n",
    "            'contacted', 'ratingRaw', 'surveyId', 'apptDateRaw', 'name', 'rating', 'comment', 'apptDate',\n",
    "            'apptProv', 'email', 'emailHref', 'respDate', 'patientContacted', 'avgRating',\n",
    "            'selectedSurveyResponseId', 'year', 'Comments'\n",
    "        ]\n",
    "    ]\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM questions\")\n",
    "    db_count = cursor.fetchone()[0]\n",
    "    assert len(question_columns) == db_count, f\"Question count mismatch: CSV={len(question_columns)}, DB={db_count}\"\n",
    "\n",
    "# Test Case 5: Data Integrity Check with date format conversion\n",
    "def test_data_integrity():\n",
    "    # Check each surveyId entry from the CSV matches data in the DB\n",
    "    for _, row in df.iterrows():\n",
    "        survey_id = row['surveyId']\n",
    "        \n",
    "        # Fetch the record from the database\n",
    "        cursor.execute(\"SELECT name, email, survey_date, appointment_date FROM surveys WHERE survey_id = %s\", (survey_id,))\n",
    "        result = cursor.fetchone()\n",
    "        \n",
    "        assert result is not None, f\"SurveyId {survey_id} not found in DB\"\n",
    "        \n",
    "        name, email, db_survey_date, db_appointment_date = result\n",
    "        \n",
    "        # Format the survey dates from both the CSV and the DB for comparison\n",
    "        csv_survey_date = format_date(row['respDate'])\n",
    "        csv_appointment_date = format_date(row['apptDate'])\n",
    "        \n",
    "        # Handle NULL email by checking if both are None (null in both CSV and DB)\n",
    "        csv_email = row['email'] if pd.notna(row['email']) else None\n",
    "        db_email = email if email is not None else None\n",
    "        \n",
    "        # Perform the assertions with the formatted dates\n",
    "        assert name == row['name'], f\"Name mismatch for SurveyId {survey_id}\"\n",
    "        assert csv_email == db_email, f\"Email mismatch for SurveyId {survey_id}: CSV={csv_email}, DB={db_email}\"\n",
    "        assert db_survey_date == csv_survey_date, f\"Survey Date mismatch for SurveyId {survey_id}: DB={db_survey_date}, CSV={csv_survey_date}\"\n",
    "        assert db_appointment_date == csv_appointment_date, f\"Appointment Date mismatch for SurveyId {survey_id}: DB={db_appointment_date}, CSV={csv_appointment_date}\"\n",
    "\n",
    "try:\n",
    "    test_survey_count()\n",
    "    test_provider_count()\n",
    "    test_response_count()\n",
    "    test_question_count()\n",
    "    test_data_integrity()\n",
    "    print(\"All tests passed successfully!\")\n",
    "except AssertionError as e:\n",
    "    print(\"Test failed:\", e)\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data cleaning for power bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv(\"C:/AMOD/finalscraped.csv\")\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def extract_roles(apptProv):\n",
    "    if not isinstance(apptProv, str):\n",
    "        apptProv = str(apptProv) \n",
    "    \n",
    "    items = re.findall(r\"['\\\"](.*?)['\\\"]\", apptProv)\n",
    "    \n",
    "    dentist = None\n",
    "    hygienist = None\n",
    "    \n",
    "    for item in items:\n",
    "        if 'Dr.' in item and dentist is None:\n",
    "            dentist = item.split('-')[0].strip()  \n",
    "        elif 'Temp Hygiene' not in item and 'Not Available' not in item and hygienist is None:\n",
    "            hygienist = item.split('-')[0].strip()\n",
    "    \n",
    "    return pd.Series([dentist, hygienist])\n",
    "\n",
    "df[['dentist', 'hygienist']] = df['apptProv'].apply(extract_roles)\n",
    "\n",
    "df = df.drop(columns=['apptProv'])\n",
    "\n",
    "df.to_csv('C:/AMOD/finalscraped1.csv', index=False)\n",
    "\n",
    "print(\"Processing complete. Data saved to 'finalscraped1.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv(\"C:/AMOD/finalscraped1.csv\")\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# List of columns that need to be imputed (excluding the ones for dentist and hygienist ratings)\n",
    "question_columns = [\n",
    "    \"Upon arriving at our dental practice, how satisfied were you with our greeting?\",\n",
    "    \"How satisfied were you with the amount of time spent in our waiting room?\",\n",
    "    \"Please rate your comfort level during your appointment?\",\n",
    "    \"How satisfied were you with your dental treatment options?\",\n",
    "    \"How likely are you to refer your friends and family to our dental office?\"\n",
    "]\n",
    "\n",
    "# Impute missing values with column averages (excluding dentist/hygienist columns)\n",
    "for col in question_columns:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# Function to get dentist/hygienist average ratings\n",
    "def impute_with_professional_rating(row, professional_type='dentist'):\n",
    "    professional_column = 'dentist' if professional_type == 'dentist' else 'hygienist'\n",
    "    professional = row[professional_column]\n",
    "    \n",
    "    if pd.notna(professional):\n",
    "        professional_rating_column = f'How would you rate your {professional_type}?'\n",
    "        professional_avg_rating = df[df[professional_column] == professional][professional_rating_column].mean()\n",
    "        return professional_avg_rating\n",
    "    else:\n",
    "        return df[f'How would you rate your {professional_type}?'].mean()\n",
    "\n",
    "# Impute missing values in \"How would you rate your dentist?\" and \"How would you rate your hygienist?\"\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isna(row[\"How would you rate your dentist?\"]):\n",
    "        df.at[index, \"How would you rate your dentist?\"] = impute_with_professional_rating(row, 'dentist')\n",
    "    \n",
    "    if pd.isna(row[\"How would you rate your hygienist?\"]):\n",
    "        df.at[index, \"How would you rate your hygienist?\"] = impute_with_professional_rating(row, 'hygienist')\n",
    "\n",
    "df.to_csv('C:/AMOD/finalscraped_imputed.csv', index=False)\n",
    "\n",
    "print(\"Imputation complete. Data saved to 'finalscraped_imputed.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentimental Analysis using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:/AMOD/finalscraped_imputed.csv\")\n",
    "df = df[[\"surveyId\",\"Comments\"]]\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_sentiment(comment):\n",
    "    sentiment = sia.polarity_scores(str(comment)) \n",
    "    return sentiment['compound']\n",
    "\n",
    "df['Sentiment Score'] = df['Comments'].apply(vader_sentiment)\n",
    "\n",
    "def classify_sentiment_vader(score):\n",
    "    if score > 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score < -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "df['Sentiment Label'] = df['Sentiment Score'].apply(classify_sentiment_vader)\n",
    "\n",
    "print(df[['Comments', 'Sentiment Score', 'Sentiment Label']])\n",
    "df.to_csv(\"C:/AMOD/Sentiments.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
